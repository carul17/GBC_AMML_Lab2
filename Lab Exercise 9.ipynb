{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:black;\"> Lab Exercise 9</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example, we will use K-Means Clustering Project database from Kaggle (https://www.kaggle.com/faressayah/k-means-clustering-private-vs-public-universities)\n",
    "# We actually have the labels for this data set, but we will NOT use them for the KMeans clustering algorithm, since that is an unsupervised learning algorithm.\n",
    "# As we will shortly see, we have a data frame with 777 observations on 18 variables.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['apps', 'accept', 'enroll', 'top10perc', 'top25perc', 'f_undergrad',\n",
       "       'p_undergrad', 'outstate', 'room_board', 'books', 'personal', 'phd',\n",
       "       'terminal', 's_f_ratio', 'perc_alumni', 'expend', 'grad_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('College_Data',index_col=0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Cazenovia College', 'grad_rate'] = 100  \n",
    "\n",
    "# Try removing various columns (features) from the dataset and examin if it improves/degrades your K-Means model performance, or it may have little impact.\n",
    "# Report 10 cases where you removed one or more features and indicate how it impacted the model performance.\n",
    "\n",
    "# Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Import SimpleImputer for handling missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Function to perform clustering and evaluate\n",
    "def evaluate_kmeans(data, features):\n",
    "    X = data[features]\n",
    "    \n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, clusters)\n",
    "    return score\n",
    "\n",
    "# Base features\n",
    "features = ['apps', 'accept', 'enroll', 'top10perc', 'top25perc', 'f_undergrad', \n",
    "           'p_undergrad', 'outstate', 'room_board', 'books', 'personal', 'phd', \n",
    "           'terminal', 's_f_ratio', 'perc_alumni', 'expend', 'grad_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (all features): 0.23186349124110617\n"
     ]
    }
   ],
   "source": [
    "# Test different feature combinations\n",
    "print(\"Baseline (all features):\", evaluate_kmeans(df, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model using all features gives us a silhouette score of 0.232, which will be our reference point for comparing feature selection impacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 1 - Without enrollment features: 0.2457449371724793\n"
     ]
    }
   ],
   "source": [
    "# Case 1: Remove enrollment related features\n",
    "features1 = [f for f in features if f not in ['enroll', 'f_undergrad', 'p_undergrad']]\n",
    "print(\"\\nCase 1 - Without enrollment features:\", evaluate_kmeans(df, features1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing enrollment features slightly improved the model performance to 0.246, suggesting these features may have been adding noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 2 - Only academic features: 0.3027706747413162\n"
     ]
    }
   ],
   "source": [
    "# Case 2: Only academic features\n",
    "features2 = ['top10perc', 'top25perc', 'phd', 'terminal', 's_f_ratio', 'grad_rate']\n",
    "print(\"\\nCase 2 - Only academic features:\", evaluate_kmeans(df, features2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only academic features improved performance to 0.303, indicating these features are strong discriminators for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 3 - Only financial features: 0.3209956280286182\n"
     ]
    }
   ],
   "source": [
    "# Case 3: Only financial features\n",
    "features3 = ['outstate', 'room_board', 'books', 'personal', 'expend']\n",
    "print(\"\\nCase 3 - Only financial features:\", evaluate_kmeans(df, features3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Financial features alone achieved a score of 0.321, showing they are also good discriminators for clustering universities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 4 - Without cost features: 0.40426435383204645\n"
     ]
    }
   ],
   "source": [
    "# Case 4: Without cost features\n",
    "features4 = [f for f in features if f not in ['outstate', 'room_board', 'books', 'personal']]\n",
    "print(\"\\nCase 4 - Without cost features:\", evaluate_kmeans(df, features4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing cost features led to a significant improvement with a score of 0.404, suggesting cost-related features may obscure underlying patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 5 - Only admission features: 0.4859216670070813\n"
     ]
    }
   ],
   "source": [
    "# Case 5: Only admission features\n",
    "features5 = ['apps', 'accept', 'top10perc', 'top25perc']\n",
    "print(\"\\nCase 5 - Only admission features:\", evaluate_kmeans(df, features5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Admission features alone produced the best performance with a score of 0.486, indicating they are the strongest predictors for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 6 - Without faculty features: 0.3809913507437334\n"
     ]
    }
   ],
   "source": [
    "# Case 6: Without faculty features\n",
    "features6 = [f for f in features if f not in ['phd', 'terminal', 's_f_ratio']]\n",
    "print(\"\\nCase 6 - Without faculty features:\", evaluate_kmeans(df, features6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing faculty features improved performance to 0.381, suggesting these features may not be essential for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 7 - Only performance indicators: 0.3634869943741708\n"
     ]
    }
   ],
   "source": [
    "# Case 7: Only performance indicators\n",
    "features7 = ['top10perc', 'top25perc', 'grad_rate', 'perc_alumni']\n",
    "print(\"\\nCase 7 - Only performance indicators:\", evaluate_kmeans(df, features7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance indicators achieved a score of 0.363, showing they are effective clustering features but not as strong as admission features alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 8 - Without application features: 0.21911848983425133\n"
     ]
    }
   ],
   "source": [
    "# Case 8: Without application features\n",
    "features8 = [f for f in features if f not in ['apps', 'accept']]\n",
    "print(\"\\nCase 8 - Without application features:\", evaluate_kmeans(df, features8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing application features slightly decreased performance to 0.219, confirming their importance in the clustering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 9 - Core features only: 0.30595321756048016\n"
     ]
    }
   ],
   "source": [
    "# Case 9: Core features only\n",
    "features9 = ['top10perc', 'outstate', 'phd', 's_f_ratio', 'grad_rate']\n",
    "print(\"\\nCase 9 - Core features only:\", evaluate_kmeans(df, features9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just core features achieved a score of 0.306, showing that a smaller set of well-chosen features can perform better than using all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case 10 - Minimal feature set: 0.3756254730397272\n"
     ]
    }
   ],
   "source": [
    "# Case 10: Minimal feature set\n",
    "features10 = ['top25perc', 'outstate', 'grad_rate']\n",
    "print(\"\\nCase 10 - Minimal feature set:\", evaluate_kmeans(df, features10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with just three features, the model achieved a score of 0.376, demonstrating that a very minimal feature set can still provide good clustering results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences\n",
    "\n",
    "From these experiments, we can draw several important inferences:\n",
    "\n",
    "1. Feature selection significantly impacts clustering performance\n",
    "2. Admission-related features (Case 5) provided the best clustering results with a score of 0.486\n",
    "3. Using fewer, well-chosen features often outperformed using all features\n",
    "4. Cost and enrollment features tended to reduce model performance when included\n",
    "5. A minimal feature set (Case 10) still performed well, suggesting some features may be redundant\n",
    "\n",
    "The optimal approach appears to be focusing on admission-related features while excluding cost and enrollment data for the best clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal feature set score: 0.4859216670070813\n",
      "\n",
      "Optimal features:\n",
      "- apps\n",
      "- accept\n",
      "- top10perc\n",
      "- top25perc\n"
     ]
    }
   ],
   "source": [
    "# Optimal feature set based on analysis\n",
    "optimal_features = ['apps', 'accept', 'top10perc', 'top25perc']\n",
    "\n",
    "# Evaluate the optimal model\n",
    "optimal_score = evaluate_kmeans(df, optimal_features)\n",
    "print(\"\\nOptimal feature set score:\", optimal_score)\n",
    "\n",
    "# Display the selected features\n",
    "print(\"\\nOptimal features:\")\n",
    "for feature in optimal_features:\n",
    "    print(f\"- {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Conclusions\n",
    "\n",
    "The optimal feature set analysis reveals several key insights:\n",
    "\n",
    "1. The highest performing model used just 4 admission-related features and achieved a silhouette score of 0.486\n",
    "2. These features (`apps`, `accept`, `top10perc`, `top25perc`) all relate to the selectivity and admission standards of universities\n",
    "3. This suggests that admission metrics are the most distinctive characteristics for clustering universities\n",
    "4. Notably absent from the optimal set are financial features (costs, expenditures) and operational features (faculty ratios, enrollment)\n",
    "5. The strong performance with just these 4 features indicates they capture the essential differences between university clusters\n",
    "\n",
    "This analysis demonstrates that while universities differ across many dimensions, their admission standards and selectivity are the most useful metrics for meaningful categorization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
