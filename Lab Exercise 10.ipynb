{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:black;\"> Lab Exercise 10</p>\n",
    "\n",
    "## Matrix Factorization with Missing Values\n",
    "\n",
    "In this exercise, we'll:\n",
    "1. Start with a complete matrix\n",
    "2. Remove some values (set to NaN)\n",
    "3. Use matrix factorization to predict the missing values\n",
    "4. Find the optimal K value (number of latent features) that gives the best predictions\n",
    "\n",
    "Since we know the original values, we can measure how well our predictions match reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(5)  # creating pseudo-random numbers for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's consider the following A_orig matrix:\n",
    "\n",
    "A_orig = np.array([[4, 2, 4, 5, 4, 2, 2], [4, 4, 3, 2, 2, 5, 4], [4, 1, 4, 7, 3, 6, 2], [8 ,1, 2, 0, 5, 0, 7], [4 , 5, 8, 7, 6, 2, 3]],dtype=float)\n",
    "M, N = 5, 7\n",
    "print (pd.DataFrame(A_orig).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some NaN(s) to  A_orig matrix\n",
    "\n",
    "A = A_orig.copy()\n",
    "A[3][1] = np.nan\n",
    "A[4][6] = np.nan\n",
    "\n",
    "A_df = pd.DataFrame(A)\n",
    "print (A_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune K value such that the (average percentage) error for the 2 missing elements is minimum.\n",
    "# Remember: this is an exercise where we have the actual values for missing elements. \n",
    "# In real-life scenarios missins elements are not known and you may need different metric(s)\n",
    "# to assess the quality of your reconstructed matrix.\n",
    "K = 1\n",
    "P = np.abs(np.random.uniform(low=0, high=8, size=(M, K)))\n",
    "Q = np.abs(np.random.uniform(low=0, high=8, size=(K, N)))\n",
    "P = np.divide(P, K*P.max())\n",
    "Q = np.divide(Q, K*Q.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(Rating_Matrix, P, Q, K, steps, alpha=0.001, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in range(steps):\n",
    "        for i in range(len(Rating_Matrix)):\n",
    "            for j in range(len(Rating_Matrix[i])):\n",
    "                if ~np.isnan(Rating_Matrix[i][j]):\n",
    "                    eij = Rating_Matrix[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eRating_Matrix = np.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in range(len(Rating_Matrix)):\n",
    "            for j in range(len(Rating_Matrix[i])):\n",
    "                if ~np.isnan(Rating_Matrix[i][j]):\n",
    "                    e = e + pow(Rating_Matrix[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        print(\"Total error at step\", step, \"is\", e)\n",
    "        if e < 0.0001:\n",
    "            break\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eP, eQ = matrix_factorization(A, P, Q.T, K, steps = 1000)\n",
    "eA = np.matmul(eP, eQ.T)\n",
    "\n",
    "print(A,'\\n')\n",
    "print(eA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Optimal K Value\n",
    "\n",
    "Now let's try different K values to see which gives us the best predictions for our missing values.\n",
    "We'll:\n",
    "- Try K values from 1 to 10\n",
    "- Run each K value multiple times (due to random initialization)\n",
    "- Calculate the average percentage error for the missing values\n",
    "- Find which K gives us the most accurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_different_k(num_trials=5):\n",
    "    # Store results for each K\n",
    "    k_results = {}\n",
    "    \n",
    "    # Try different K values\n",
    "    for k in range(1, 11):  # Try K from 1 to 10\n",
    "        k_errors = []\n",
    "        \n",
    "        # Multiple trials for each K to account for random initialization\n",
    "        for trial in range(num_trials):\n",
    "            # Initialize matrices with current K\n",
    "            P = np.abs(np.random.uniform(low=0, high=8, size=(M, k)))\n",
    "            Q = np.abs(np.random.uniform(low=0, high=8, size=(k, N)))\n",
    "            P = np.divide(P, k*P.max())\n",
    "            Q = np.divide(Q, k*Q.max())\n",
    "            \n",
    "            # Run matrix factorization\n",
    "            eP, eQ = matrix_factorization(A, P, Q.T, k, steps=1000)\n",
    "            eA = np.matmul(eP, eQ.T)\n",
    "            \n",
    "            # Calculate error for missing values (comparing with A_orig)\n",
    "            error = (abs(eA[3,1] - A_orig[3,1])/A_orig[3,1] + \n",
    "                    abs(eA[4,6] - A_orig[4,6])/A_orig[4,6]) / 2\n",
    "            k_errors.append(error)\n",
    "        \n",
    "        # Store average error across trials for this K\n",
    "        k_results[k] = np.mean(k_errors)\n",
    "        print(f\"K={k}, Average Error across {num_trials} trials: {k_results[k]:.4f}\")\n",
    "    \n",
    "    # Find best K\n",
    "    best_k = min(k_results.items(), key=lambda x: x[1])\n",
    "    print(f\"\\nBest K value: {best_k[0]} with average error: {best_k[1]:.4f}\")\n",
    "    return k_results, best_k\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Run the optimization with 5 trials per K value\n",
    "k_results, best_k = try_different_k(num_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(list(k_results.keys()), list(k_results.values()), 'bo-')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Average Error')\n",
    "plt.title('Error vs K Value in Matrix Factorization')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "From our experiments with different K values:\n",
    "\n",
    "1. The optimal K value was found to be 2, showing the lowest average error in our experiments\n",
    "2. This suggests that 2 latent features are sufficient to capture the underlying patterns in our matrix\n",
    "3. The error trend shows:\n",
    "   - K=1 underfits the data (too simple to capture all patterns)\n",
    "   - K values above 2 show higher errors, suggesting potential overfitting\n",
    "   - The error increases after K=2, indicating additional features may be introducing noise\n",
    "\n",
    "This optimal K=2 value provides the best balance between model complexity and prediction accuracy for our missing values (A[3,1]=1 and A[4,6]=3)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
