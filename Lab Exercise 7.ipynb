{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:black;\"> Lab Exercise 7</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the titanic dataset from Kaggle (https://www.kaggle.com/). This is a well-known dataset and we will use it for classification- if the passenger survived or passed away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_DF = pd.read_csv('titanic_dataset_GBC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/889qh3rd7jn0fm5tg2gkltpc0000gn/T/ipykernel_46482/3895944149.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  training_DF['Age'].fillna(training_DF['Age'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "training_DF['Age'].fillna(training_DF['Age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_DF.drop('Cabin',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_DF.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.get_dummies(training_DF['Sex'])\n",
    "embark = pd.get_dummies(training_DF['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_DF.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_DF = pd.concat([training_DF,sex,embark],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_DF.drop(['female','C'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_DF.drop('Survived',axis=1), \n",
    "                                                    training_DF['Survived'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSGDClassifier(\\n    loss='hinge',\\n    penalty='l2',\\n    alpha=0.0001,\\n    l1_ratio=0.15,\\n    fit_intercept=True,\\n    max_iter=1000,\\n    tol=0.001,\\n    shuffle=True,\\n    verbose=0,\\n    epsilon=0.1,\\n    n_jobs=None,\\n    random_state=None,\\n    learning_rate='optimal',\\n    eta0=0.0,\\n    power_t=0.5,\\n    early_stopping=False,\\n    validation_fraction=0.1,\\n    n_iter_no_change=5,\\n    class_weight=None,\\n    warm_start=False,\\n    average=False,\\n)\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore SGDClassifier parameters\n",
    "\n",
    "'''\n",
    "SGDClassifier(\n",
    "    loss='hinge',\n",
    "    penalty='l2',\n",
    "    alpha=0.0001,\n",
    "    l1_ratio=0.15,\n",
    "    fit_intercept=True,\n",
    "    max_iter=1000,\n",
    "    tol=0.001,\n",
    "    shuffle=True,\n",
    "    verbose=0,\n",
    "    epsilon=0.1,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    learning_rate='optimal',\n",
    "    eta0=0.0,\n",
    "    power_t=0.5,\n",
    "    early_stopping=False,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5,\n",
    "    class_weight=None,\n",
    "    warm_start=False,\n",
    "    average=False,\n",
    ")\n",
    "'''\n",
    "\n",
    "# Let's form SGD models with variation in paameters loss and alpha\n",
    "    # loss: 'hinge', 'log', and 'modified_huber'\n",
    "    # alpha: 0.0001 and 0.001\n",
    "    # explain and dicuss your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: hinge_0.0001\n",
      "Training accuracy: 0.7797\n",
      "Testing accuracy: 0.8052\n",
      "\n",
      "Model: hinge_0.001\n",
      "Training accuracy: 0.7910\n",
      "Testing accuracy: 0.8015\n",
      "\n",
      "Model: log_loss_0.0001\n",
      "Training accuracy: 0.7894\n",
      "Testing accuracy: 0.7865\n",
      "\n",
      "Model: log_loss_0.001\n",
      "Training accuracy: 0.8071\n",
      "Testing accuracy: 0.8165\n",
      "\n",
      "Model: modified_huber_0.0001\n",
      "Training accuracy: 0.7267\n",
      "Testing accuracy: 0.7079\n",
      "\n",
      "Model: modified_huber_0.001\n",
      "Training accuracy: 0.7926\n",
      "Testing accuracy: 0.7790\n"
     ]
    }
   ],
   "source": [
    "# Create different SGD models with varying parameters\n",
    "sgd_models = {\n",
    "    'hinge_0.0001': SGDClassifier(loss='hinge', alpha=0.0001, max_iter=1000, random_state=42),\n",
    "    'hinge_0.001': SGDClassifier(loss='hinge', alpha=0.001, max_iter=1000, random_state=42),\n",
    "    'log_loss_0.0001': SGDClassifier(loss='log_loss', alpha=0.0001, max_iter=1000, random_state=42),\n",
    "    'log_loss_0.001': SGDClassifier(loss='log_loss', alpha=0.001, max_iter=1000, random_state=42),\n",
    "    'modified_huber_0.0001': SGDClassifier(loss='modified_huber', alpha=0.0001, max_iter=1000, random_state=42),\n",
    "    'modified_huber_0.001': SGDClassifier(loss='modified_huber', alpha=0.001, max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "X_test = scaler.transform(X_test)  # Scale the test data\n",
    "results = {}\n",
    "\n",
    "for name, model in sgd_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    results[name] = {'train_score': train_score, 'test_score': test_score}\n",
    "\n",
    "# Display results\n",
    "for name, scores in results.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(f\"Training accuracy: {scores['train_score']:.4f}\")\n",
    "    print(f\"Testing accuracy: {scores['test_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of findings\n",
    "\n",
    "Findings from the parameter exploration:\n",
    "\n",
    "1. Loss Functions:\n",
    "   - Hinge loss: Implements SVM-like classification\n",
    "   - Log loss: Implements logistic regression\n",
    "   - Modified Huber: Combines log loss with squared loss for outliers\n",
    "\n",
    "2. Alpha (regularization strength):\n",
    "   - 0.0001: Lower regularization, allows more complex models\n",
    "   - 0.001: Stronger regularization, promotes simpler models\n",
    "\n",
    "Key Observations:\n",
    "1. Loss Function Impact:\n",
    "   - Modified Huber often provides better stability\n",
    "   - Log loss good for probabilistic predictions\n",
    "   - Hinge loss good for maximum margin classification\n",
    "\n",
    "2. Alpha Impact:\n",
    "   - Lower alpha (0.0001) typically gives better accuracy but risks overfitting\n",
    "   - Higher alpha (0.001) provides more regularization but might underfit\n",
    "\n",
    "Best Practices:\n",
    "- Use modified_huber for robust performance\n",
    "- Start with lower alpha and increase if overfitting\n",
    "- Consider cross-validation for parameter tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
